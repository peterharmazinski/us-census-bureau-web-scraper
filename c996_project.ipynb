{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Census Bureau URI Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import bs4, csv\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from urllib.parse import urljoin, urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the html from the census bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'http://www.census.gov/programs-surveys/popest.html'\n",
    "request = requests.get(link)\n",
    "raw_html = request.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the raw html into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_html_file = open('raw_html.html', 'w')\n",
    "raw_html_file.write(raw_html)\n",
    "raw_html_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the links in the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = BeautifulSoup(raw_html, 'html.parser')\n",
    "a = html.find_all('a')\n",
    "hrefs = map(lambda x: x.get('href'), a)\n",
    "links_list = list(hrefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out invalid links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nulls = pd.Series(links_list).dropna()\n",
    "uniques = set(non_nulls[~non_nulls.str.startswith('#')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the links to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully created. urls_count=117\n"
     ]
    }
   ],
   "source": [
    "with open('urls.csv', 'w', newline='') as urls_file:\n",
    "    cw = csv.writer(urls_file)\n",
    "    cw.writerows([['urls']])\n",
    "    for url in uniques:\n",
    "        if ~url.startswith('http'):\n",
    "            url = str(urljoin('http://www.census.gov/programs-surveys/popest.html/', url)).strip('/')\n",
    "        if url != 'http://www.census.gov/programs-surveys/popest.html':\n",
    "            # only write the url to the file if it's not the source site's address\n",
    "            cw.writerows([[url]])\n",
    "print(f'CSV file successfully created. urls_count={len(uniques)}')\n",
    "urls_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
